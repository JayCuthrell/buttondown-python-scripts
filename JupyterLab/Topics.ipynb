{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d7a4cf-9f7d-442c-b64d-1e64273c7e01",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Topics.ipnyb\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "The script analyzes Markdown files (.md) in a specific folder on your computer. It extracts the text, cleans it up, and then identifies the most and least common words, two-word phrases (bigrams), and three-word phrases (trigrams). This helps you understand the key topics and language patterns in your documents.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Setup:**\n",
    "   - Import necessary libraries: `glob`, `markdown`, `re`, `nltk`, `collections.Counter`, `nltk.tokenize`, `nltk.corpus`, `nltk.util`, and `bs4`.\n",
    "   - Download NLTK data: Ensures the script has the required language resources (tokenizers, stop words).\n",
    "   - Define the folder path: Specifies the directory where your Markdown files are located.\n",
    "\n",
    "2. **Load and Prepare Text:**\n",
    "   - Find Markdown files: Uses `glob.glob` to get a list of all `.md` files in the specified folder.\n",
    "   - Read and concatenate text: Opens each file, converts Markdown to plain text using `markdown`, and combines the text from all files into one string.\n",
    "   - Remove HTML tags: Uses `BeautifulSoup` to strip out any HTML code that might be present.\n",
    "   - Clean text:\n",
    "      - Removes punctuation and converts everything to lowercase.\n",
    "      - Tokenizes the text into individual words using `word_tokenize`.\n",
    "\n",
    "3. **Filter Words:**\n",
    "   - Define filter lists: Creates sets of words to exclude from the analysis:\n",
    "      - `weasel_words`: Words that are vague or lack specific meaning (e.g., \"actually,\" \"probably\").\n",
    "      - `days_of_week`: Names of days and \"timeline.\"\n",
    "      - `months`: Names of months (full and abbreviated).\n",
    "      - `week_variations`: Variations of the word \"week.\"\n",
    "      - `stopwords`: Common words with little meaning (e.g., \"the,\" \"and\").\n",
    "   - Combine filters: Merges all these lists into one set for efficiency.\n",
    "   - Filter out words: Keeps only words that are not in the filter list and are not numbers.\n",
    "\n",
    "4. **Analyze Text:**\n",
    "   - Calculate word frequencies:  Uses `Counter` to count how often each word appears.\n",
    "   - Find top words: Gets the 25 most frequent words and their counts.\n",
    "   - Create bigrams and trigrams: Forms two-word and three-word phrases using `ngrams`.\n",
    "   - Count n-gram frequencies: Similar to word counts, but for phrases.\n",
    "   - Find top n-grams: Gets the 25 most frequent bigrams and trigrams.\n",
    "   - Find least common trigrams: Gets the 5 least frequent trigrams.\n",
    "\n",
    "5. **Display Results:**\n",
    "   - Print the 5 least common, 25 most common trigrams, 25 most common words, and 25 most common bigrams, along with their counts.\n",
    "\n",
    "**Customization:**\n",
    "    - This script can be modified by adjusting:\n",
    "       - folder_path to reflect the actual directory containing your markdown files\n",
    "       - words in the weasel_words list to add or remove words to ignore from the analysis\n",
    "       - the number of common words or phrases to print to adjust the scope of your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17957666-e9c7-4bf7-9c27-0f7982fcc15c",
   "metadata": {},
   "source": [
    "# Setup your environent\n",
    "\n",
    "- Use pip to upgrade pip\n",
    "- install pandas, requests, markdown, textblob, nltk, gensim, spacy, beautifulsoup4\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4fee2-df75-47c3-b750-d0e9cc966878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd75ea-7625-478c-a97b-0fefae91ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625299e-9f0e-49af-bccf-836a0eb35f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb52584-5de1-41d6-a05b-018172619a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be840945-a3f8-42a8-b90c-dfe15987654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad50e0-3f9e-4bd7-83ab-ff9046c6c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4ef9a-be56-4f22-8759-2b0a96536362",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad5a64-bee1-44d0-b5e8-817eae9ae5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036e284-be40-4374-816f-d148b6eec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2abd9-b732-455d-b991-7d80ea475f87",
   "metadata": {},
   "source": [
    "# Customize for your needs \n",
    "\n",
    "- Update the ```folder path```\n",
    "- Run the script to see what updates you want to append to ```weasel_words```\n",
    "- Alter the numerical values for returned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689870ed-59c1-4f20-bdbf-ffb4cb992cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import markdown\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download NLTK data if needed\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('stopwords')  # For stop word removal\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# 1. Define Folder Path and Load Markdown Files\n",
    "folder_path = '/path/to/your/blog/posts/*.md'  # Your folder path\n",
    "markdown_files = glob.glob(folder_path)\n",
    "all_text = \"\"\n",
    "\n",
    "for file_path in markdown_files:\n",
    "    with open(file_path, 'r') as file:\n",
    "        md_text = file.read()\n",
    "        plain_text = markdown.markdown(md_text)\n",
    "\n",
    "        # Remove HTML tags\n",
    "        soup = BeautifulSoup(plain_text, 'html.parser')\n",
    "        plain_text = soup.get_text()\n",
    "\n",
    "        all_text += plain_text + \" \" \n",
    "\n",
    "# 2. Clean and Preprocess Text\n",
    "all_text = re.sub(r'[^\\w\\s]', '', all_text).lower() \n",
    "words = word_tokenize(all_text)\n",
    "\n",
    "# Extended list of words to filter out\n",
    "\n",
    "weasel_words = {\"subscribe\", \"pulls\", \"self\", \"oooh\", \"wow\", \"nice\", \"thats\", \"grocery\", \"store\", \n",
    "                \"headroom\", \"shot\"} # Add your words\n",
    "\n",
    "days_of_week = {\"timeline\", \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"}\n",
    "months = {\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\",\n",
    "          \"october\", \"november\", \"december\", \"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\",\n",
    "          \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"}  # Added abbreviations\n",
    "week_variations = {\"week\", \"weeks\", \"weekly\"}\n",
    "\n",
    "words_to_filter = set(stopwords.words('english'))\n",
    "words_to_filter.update(weasel_words, days_of_week, months, week_variations) \n",
    "\n",
    "# Filter out words that are numbers\n",
    "filtered_words = [word for word in words if not word in words_to_filter and not word.isdigit()]\n",
    "\n",
    "# 3. Analyze for Most Common Words, Bigrams, and Trigrams\n",
    "word_counts = Counter(filtered_words)\n",
    "top_words = word_counts.most_common(25)\n",
    "\n",
    "bigrams = ngrams(filtered_words, 2)\n",
    "bigram_counts = Counter(bigrams)\n",
    "top_bigrams = bigram_counts.most_common(25)\n",
    "\n",
    "trigrams = ngrams(filtered_words, 3)\n",
    "trigram_counts = Counter(trigrams)\n",
    "top_trigrams = trigram_counts.most_common(25)\n",
    "\n",
    "# Get the 5 least common trigrams\n",
    "least_common_trigrams = trigram_counts.most_common()[-5:] \n",
    "# Note:  We reverse the order using `[-5:]` to get the least common ones.\n",
    "\n",
    "print(\"\\nTop 5 Least Common Three-Word Phrases:\")\n",
    "for trigram, count in least_common_trigrams:\n",
    "    print(f\"{trigram}: {count}\")  \n",
    "\n",
    "print(\"\\nTop 25 Most Common Three-Word Phrases:\")\n",
    "for trigram, count in top_trigrams:\n",
    "    print(f\"{trigram}: {count}\")\n",
    "\n",
    "print(\"\\nTop 25 Most Common Words:\")\n",
    "for word, count in top_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 25 Most Common Two-Word Phrases:\")\n",
    "for bigram, count in top_bigrams:\n",
    "    print(f\"{bigram}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d76c1e-8b93-42ed-b763-0d9554396053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
